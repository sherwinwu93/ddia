# Chapter3 Storage and Retrieval
store and get data
SQL and NoSQL

Having a rough idea about storage engine is good for you to choose storage engines.
Transaction Processing VS Analytics
Column-Oriented Storage
Log-structured (NoSQL?) vs page-oriented(SQL B-trees)

## Data Structures That Power Your Database

Trade-off in storage system: indexes speed up reads and slow down writes

Real databases need to deal with concurrency control, reclaiming disk space, handling errors, partially written records.

-- simplest database
```bash
db_set() { echo "$1,$2" >> database }
db_get() { grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 }
```
It writes efficiently(O(1)), but slow to read.(O(n))

Index affects performance instead of primary data.
Slow down writes and updates, but speeds up reads.

Therefore, you can choose index to speed up reads at the cost of slowing down writes and updates.

### Hash Indexes
Hash Index: key-value, building block for complex indexes

hash map not only used in in-memory data structures, but also in disk storage.

while appending a new key-value, also update hashmap to reflect the offset of the data.

Bitcask keeps all offsets in memory.

When key changed less frequently than values, it's good.

When a segment is full, create a new segment. Compaction means throwing away duplicate keys.

Merge: merge old segments into one, then delete old segments. While merging, we still reads old segments.

When looking up, we first check the most recent segments then the second-recent segments.

Issues in practice:
- File format: not CSV, but a binary format
- Deleting records: add a deletion record, when merging it deletes all records that're before it.
- Crash recovery: To speed up hash, we keep a copy of it in disk to use it while restarting.
- Partially written records: Checksums to detect corrupted parts.
- Concurrency control: only one writer thread, many read threads.

Why append-only not overwriting?
- Write operations are sequential.
- Concurrency and crash recovery are simple.
- Merging avoids files getting fragmented.
Limitations:
- Cost a lot of memory
- Range queries: not efficient

:wusd
Hash Index: keep data's position in memory.
    - Compaction(throw away duplicate key) and Merge: merge old segments into one, then delete old segments.
    - Lookup: first check the most-recent segments then the second-recent segments.
    - Issues and solutions: 
        + File format(binary)
        + Deleting records(add flag and delete previous)
        + Crash recovery: Keep a copy of hashmap in disk
        + Partially written records: Checksums to detect corrupted parts.
        + Concurrency control: only one writer thread, many read threads.
    - advantages:
        + sequential writes
        + Concurrency and crash recovery are simple.
        + Merging avoids files getting fragmented.
    - disadvantages:
        + Cost a lot of memory
        + Range queries are not efficient

### SSTables and LSM-Trees
SSTables: Sorted String Tables
LSM-Trees: Log-Structured Merge-Trees
------------
--
Sorted String Table: Make our segment files sorted by key.
Each key only appears once in merged segment file.
advantages:
1. Merging is simple and efficient, requiring less memory. Meeting the same key while merging, we keep most-recent segment's value.
2. No longer need to keep all keys in memory.
3. Group records of range into a block and compress it. It saves disk space and bandwidth.

#### Constructing and maintaining SSTables
--
Using red-black trees or AVL trees to implement SSTables.
How our storage engine works:
- When writing, add it to an in-memory balanced tree(memtable)
- After memtable is bigger than threshold, write it to most recent segment and use a new memtable instance.
- When reading, lookup in memtable, then in SSTables.
- Run a merging and compaction process in the background to merge segments and to discard overwritten or deleted values.

In order to avoid memtable losting, we keep a separate log on disk which is used to restore memtable.

#### Making an LSM-Tree out of SSTables
The applications that use memtable and SSTables: LevelDB, RocksDB, Google's Bigtable.

LSM: Log-Structured Merge-Trees(the indexing structure: merging and compacting sorted file)

Lucene's term dictionary.

#### Performance optimizations
Additional Bloom filter optimize the situation in which you are looking up keys that doesn't exist.

In size tiered compaction: newer and smaller SSTables are merged into older and  larger SSTables.
In leveled compaction: it's like sorting a massive, messy pile of papers into a series of organized filing cabinets.

Basic idea of LSM-trees: keeping a cascade of SSTables merge in the background.

:wusd
SSTables(units): Sorted String Tables
    - characteristics:  key sorted and only appearing once in every segment
    - advantages:
        + Merge simple,cost few memory
        + No need to keep all keys in memory
        + Group records of range into a block and compress it
    - how storage engine works:
        + Write records to memtable(balanced tree)
        + Write memtable to most recent segment and use a new memtable instance after memtable is big enough.
        + A merging and compaction process in bg to merge segments and to discard useless record.
        + Keep a separate log on disk in case of losing memetable after crush.
LSM-Trees(architecture): Log-Structured Merge-Trees
    - apps: LevelDB, RocksDB, Google's Bigtable, Lucene
    - optimizations: Bloom filter, size tiered compaction(small to big), leveled compaction(messy papers to ordered cabinets)

### B-Trees
B-Tree is most widely used.

Key-value sorted by key, which allows efficient key-value lookups and range queries.

B-trees have fixed-size blocks or pages(4KB), read or write one page at a time, corresponding to disks which are arranged in fixed-size blocks.

Root page contains several keys and references to child pages which also have continuous keys and references.

Leaf page contains value or references to the pages where values can be found.

The branching factor: the number of references to child pages.(typically several hundred)

update: find the leaf page, change the value in that page, and write the page back to disk.
add: find the page whose range encompasses, add it to that page.
    If space is not enough, split into two half-full pages, and parent page is updated.

Balanced: O(logn), four-level of 4KB pages, 500 factor, 256TB.

#### Making B-trees reliable
The overwrite of B-tree doesn't change location of page. LSM-trees, append to files.

When splitting up page, if it runs into crash, the child page may be an orphan.
    So there's a write-ahead log(appending only) to restore B-tree.

#### B-tree optimizations
Optimizations:
    - Instead of WAL, copy-on-write scheme: LeafPage(New), Parent(New), Root(New)
    - Abbreviating key which only need to provide enough information of ranges.
    - Keep them sequential on disk. It's not easy for B-tree, but easy for LSM-trees.
    - leaf page have references to its sibling pages, no need to jump back to parent pages.
    - B-tree variants like log-structured.


### Comparing B-Trees and LSM-Trees
B-Trees is faster for reads, LSM-Trees for writes.

However, you have to test them with your particular workload.

#### Advantages of LSM-trees
B-tree index must write twice,(WAL and itself).

Log-structured indexes rewrite data many times because of compaction and merge.(write amplification)

The performance bottleneck of write-heavy can be the rate of disk.

LSM-trees typically has higher throughput than B-trees, partly because of lower write amplification,
partly because write sequentially rather than overwriting several pages in the tree.

LSM-tree can be compressed better, compaction and merge remove fragmentation.
So they have lower storage overheads than B-trees.

--

#### Downsides of LSM-trees
The compaction process can interfere with ongoing reads and writes, 
    throughput and average response time is usually good, but sometime the response time can be quite high.

At high write throughput, disk's write bandwidth is shared between initial write and compaction threads.

The compaction cannot keep up with the rate of writes, unmerged segments increase, and disk is used up.
Reads slow down because of more segment files.

Because each key in B-trees in exactly one place, we can lock up the key directly so that transaction is easy. 

### Other Indexing Structures
primary key, secondary indexes, key-value index

A primary key identifies one row, or one document, or one vertex.(like ID in SQL)

Secondary indexes is often not unique(like Index In SQL).
A key with a posting list in a full-text index, or appending a row identifier to it.

#### Storing values within the index
Index: key+value, key+references(refer to heap file, it's common because of duplication).

Updating heap file, when it doesn't change location, just update it.
When it changes location, needs to change all references in indexes.

Clustered index(storing all row data within the index) doesn't need to change location.

A compromise between clustered index and a nonclustered index.(Cover index)

#### Multi-column indexes
A concatenated index like phone book, (lastname, firstname, phone).
However, it's useless if you want to find all the people with a firstname.

Multi-dimensional indexes(R-trees), translate a two-dimensional location into a single number then B-trees.
```sql
SELECT * FROM restaurants WHERE latitude > 51.4946 AND latitude < 51.5079
    AND longitude > -0.1162 AND longitude < -0.1004;
```
More examples: (red, green, blue) for color, (date, temperature) for a day.

#### Full-text search and fuzzy indexes
Search for similar keys, misspelled words.

#### Keeping everything in memory
Keep data in memory in several machines.

Battery-powered RAM write changes to disk, periodic snapshots to disk, replicating state to other machines.

Its performance advantage is not due to the fact that it doesn't need to read from disk.
Rather, they can avoid encoding in-memory data structures in a form that can be written to disk.

In-memory indexes are easier than disk-based indexes.

In-memory database architecture could support datasets larger than the available memory.(Anti-caching)
Evicting least recently used data from memory to disk, loading it back in memory when it's accessed again.

Non-volatile memory.

## Transaction Processing or Analytics?
Transaction refers to a group of reads and writes that form a logical unit.

Because applications are interactive, the access pattern is known as online transaction processing(OLTP).

Online analytic processing(OLAP).
Analytic queries:
    - total revenue
    - more bananas we sell during the promotion
    - Which band of baby food is most often purchased

Stop using OLTP systems for analytics purposes, but use a data warehouse to analysis.

### Data Warehousing

Data warehouse extract, and transform data from many DBs of OLTP systems, like Sales DB, Inventory DB, Geo DB.

#### The divergence between OLTP databases and data warehouses
Although OLTP and OLAP both have a SQL query interface, the internals of the systems are optimized for different query patterns.

### Stars and Snowflakes: Schemas for Analytics
star schema(dimensional modeling): 
    the fact table is in the middle, surrounded by its dimension tables, the connections are like the rays of a star.

Fact table, each row of that represents an event, like a customer's purchase of a product.
Which can be very large.

Holidays and non-holidays.


Snowflake schema, which dimensions are further broken down into subdimensions.


## Column-Oriented Storage

## Summary
how databases handle storage and retrieval

OLTP: optimized for transaction processing
    end users use key, then engine uses indeces to find data
    bottleneck: Disk seek time 
OLAP: optimized for analytics
    Data warehouses(数仓)
    bottleneck: Disk bandwidth

two main school for OLTP:
- log-structured school: only create and delete, no writing
    turn random-access writes into sequential
- update-in-place school: CUD, B-trees example
 
indexing structures, and databases that keep all data in memory

OLTP: when scanning across many rows, encoding data compactly are more important than indexes.
column-oriented storage achieved this goal.

As a developer, the knowledge about internals of storage engines help you find tool better suited.

vocabulary and ideas about database