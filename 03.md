# Chapter3 Storage and Retrieval
store and get data
SQL and NoSQL

Having a rough idea about storage engine is good for you to choose storage engines.
Transaction Processing VS Analytics
Column-Oriented Storage
Log-structured (NoSQL?) vs page-oriented(SQL B-trees)

## Data Structures That Power Your Database

Trade-off in storage system: indexes speed up reads and slow down writes

Real databases need to deal with concurrency control, reclaiming disk space, handling errors, partially written records.

-- simplest database
```bash
db_set() { echo "$1,$2" >> database }
db_get() { grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 }
```
It writes efficiently(O(1)), but slow to read.(O(n))

Index affects performance instead of primary data.
Slow down writes and updates, but speeds up reads.

Therefore, you can choose index to speed up reads at the cost of slowing down writes and updates.

### Hash Indexes
Hash Index: key-value, building block for complex indexes

hash map not only used in in-memory data structures, but also in disk storage.

while appending a new key-value, also update hashmap to reflect the offset of the data.

Bitcask keeps all offsets in memory.

When key changed less frequently than values, it's good.

When a segment is full, create a new segment. Compaction means throwing away duplicate keys.

Merge: merge old segments into one, then delete old segments. While merging, we still reads old segments.

When looking up, we first check the most recent segments then the second-recent segments.

Issues in practice:
- File format: not CSV, but a binary format
- Deleting records: add a deletion record, when merging it deletes all records that're before it.
- Crash recovery: To speed up hash, we keep a copy of it in disk to use it while restarting.
- Partially written records: Checksums to detect corrupted parts.
- Concurrency control: only one writer thread, many read threads.

Why append-only not overwriting?
- Write operations are sequential.
- Concurrency and crash recovery are simple.
- Merging avoids files getting fragmented.
Limitations:
- Cost a lot of memory
- Range queries: not efficient

:wusd
Hash Index: keep data's position in memory.
    - Compaction and Merge: merge old segments into one, then delete old segments.
    - Lookup: first check the most-recent segments then the second-recent segments.
    - Issues and solutions: 
        + File format(binary)
        + Deleting records(add flag and delete previous)
        + Crash recovery: Keep a copy of hashmap in disk
        + Partially written records: Checksums to detect corrupted parts.
        + Concurrency control: only one writer thread, many read threads.
    - advantages:
        + sequential writes
        + Concurrency and crash recovery are simple.
        + Merging avoids files getting fragmented.
    - disadvantages:
        + Cost a lot of memory
        + Range queries are not efficient

### SSTables and LSM-Trees
SSTables: Sorted String Tables
LSM-Trees: Log-Structured Merge-Trees
------------
--
Sorted String Table: Make our segment files sorted by key.
Each key only appears once in merged segment file.
advantages:
1. Merging is simple and efficient, requiring less memory. Meeting the same key while merging, we keep most-recent segment's value.
2. No longer need to keep all keys in memory.
3. Group records of range into a block and compress it. It saves disk space and bandwidth.

#### Constructing and maintaining SSTables
--
Using red-black trees or AVL trees to implement SSTables.
How our storage engine works:
- When writing, add it to an in-memory balanced tree(memtable)
- After memtable is bigger than threshold, write it to most recent segment and use a new memtable instance.
- When reading, lookup in memtable, then in SSTables.
- Run a merging and compaction process in the background to merge segments and to discard overwritten or deleted values.

In order to avoid memtable losting, we keep a separate log on disk which is used to restore memtable.

#### Making an LSM-Tree out of SSTables
The applications that use memtable and SSTables: LevelDB, RocksDB, Google's Bigtable.

LSM: Log-Structured Merge-Trees(the indexing structure: merging and compacting sorted file)

Lucene's term dictionary.

#### Performance optimizations
Additional Bloom filter optimize the situation in which you are looking up keys that doesn't exist.

In size tiered compaction: newer and smaller SSTables are merged into older and  larger SSTables.
In leveled compaction: it's like sorting a massive, messy pile of papers into a series of organized filing cabinets.

Basic idea of LSM-trees: keeping a cascade of SSTables merge in the background.

:wusd
SSTables(units): Sorted String Tables
    - characteristics:  key sorted and only appearing once in every segment
    - advantages:
        + Merge simple,cost few memory
        + No need to keep all keys in memory
        + Group records of range into a block and compress it
    - how storage engine works:
        + Write records to memtable(balanced tree)
        + Write memtable to most recent segment and use a new memtable instance after memtable is big enough.
        + A merging and compaction process in bg to merge segments and to discard useless record.
        + Keep a separate log on disk in case of losing memetable after crush.
LSM-Trees(architecture): Log-Structured Merge-Trees
    - apps: LevelDB, RocksDB, Google's Bigtable, Lucene
    - optimizations: Bloom filter, size tiered compaction(small to big), leveled compaction(messy papers to ordered cabinets)

### B-Trees

### Comparing B-Trees and LSM-Trees

### Other Indexing Structures

#### Storing values within the index

#### Multi-column indexes

#### Full-text search and fuzzy indexes

#### Keeping everything in memory

## Transaction Processing or Analytics?

## Column-Oriented Storage

## Summary
how databases handle storage and retrieval

OLTP: optimized for transaction processing
    end users use key, then engine uses indeces to find data
    bottleneck: Disk seek time 
OLAP: optimized for analytics
    Data warehouses(数仓)
    bottleneck: Disk bandwidth

two main school for OLTP:
- log-structured school: only create and delete, no writing
    turn random-access writes into sequential
- update-in-place school: CUD, B-trees example
 
indexing structures, and databases that keep all data in memory

OLTP: when scanning across many rows, encoding data compactly are more important than indexes.
column-oriented storage achieved this goal.

As a developer, the knowledge about internals of storage engines help you find tool better suited.

vocabulary and ideas about database